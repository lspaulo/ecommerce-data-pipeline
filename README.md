## Pipeline de Dados E-commerce

![Badge ConcluÃ­do](https://img.shields.io/badge/STATUS-CONCLU%C3%8DDO-success?style=for-the-badge&color=4CAF50)
## ğŸ“Œ VisÃ£o Geral

Pipeline de dados para processamento de informaÃ§Ãµes de e-commerce, implementando um fluxo ELT (Extract, Load, Transform) com:
- ExtraÃ§Ã£o de dados brutos (RAW)
- Processamento para camada Bronze (dados crus)
- TransformaÃ§Ã£o para camada Silver (dados limpos e tratados)
- AgregaÃ§Ãµes para camada Gold (dados analÃ­ticos)

## ğŸ“‹ Funcionalidades

- `ExtraÃ§Ã£o`: Carrega dados CSV do S3 para a camada Bronze em formato Parquet
- `TransformaÃ§Ã£o Bronzeâ†’Silver`: 
  - Filtra pedidos com status "delivered"
  - Remove valores nulos
- `TransformaÃ§Ã£o Silverâ†’Gold`:
  - **LogÃ­stica**: Agrega pedidos por estado/cidade
  - **Financeiro**: Calcula valor total por cliente

## ğŸ›  Tecnologias Utilizadas

- **Apache Airflow**: OrquestraÃ§Ã£o do pipeline
- **AWS S3**: Armazenamento de dados
- **PyArrow/Parquet**: Formato de arquivo columnar
- **Pandas**: Processamento de dados
- **Python 3**: Linguagem principal

## ğŸ— Estrutura do Projeto
- ğŸ“ **DNC-DATA-ENGINEER/**
  - ğŸ“ `airflow/` - _ConfiguraÃ§Ãµes do Airflow_
  - ğŸ“ `app/` - _CÃ³digo fonte_
    - ğŸ“„ `extractor_loader.py` - ExtraÃ§Ã£o RAWâ†’Bronze
    - ğŸ“„ `transformer.py` - TransformaÃ§Ãµes Bronzeâ†’Silverâ†’Gold
  - ğŸ“ `dags/` - _DAGs do Airflow_
    - ğŸ“„ `orders_dag.py` - Pipeline principal
  - ğŸ“ `config/` - _Arquivos de configuraÃ§Ã£o_
  - ğŸ“ `datasources/` - _Notebooks de exploraÃ§Ã£o_
  - ğŸ“ `input-data/` - _Dados de exemplo locais_
  - ğŸ“„ `docker-compose.yaml` - _ConfiguraÃ§Ã£o do Airflow_
  - ğŸ“„ `.env` - _VariÃ¡veis de ambiente_
  - 
### ğŸ“Š Diagrama de Fluxo
```mermaid
graph TD
    A[ğŸ“¥ Extract: CSV do S3] -->|Carrega dados brutos| B[ğŸŸ¤ Bronze: Parquet]
    B -->|Remove nulos| C[âšª Silver: Dados tratados]
    C -->|Agrega por local| D[ğŸŸ¡ Gold: LogÃ­stica]
    C -->|Soma pagamentos| E[ğŸŸ¢ Gold: Financeiro]
